{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 04:03:08.792774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/codes')\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pricing_model import get_gamma\n",
    "from agent import MVPITD3Agent\n",
    "from utils import Config, MeanStdNormalizer\n",
    "from Envs import DeltaHedgingEnv, DeltaHedgingEnvTiming\n",
    "from component import Task\n",
    "from component.replay import *\n",
    "from component.random_process import *\n",
    "from network import GaussianActorCriticNet, FCBody, TwoLayerFCBodyWithAction, ThreeLayerFCBodyWithAction, TD3Net, RTD3Net, OneDenseLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config(trial_no, gpu_no=0, model_dir='./codes/model/'):\n",
    "    # search existing model name\n",
    "    file_list = [x for x in os.listdir(model_dir) if x.endswith('.model') and x.startswith(f't{trial_no}')]\n",
    "    last_dash = file_list[0].rfind('-')\n",
    "    model_name = file_list[0][:last_dash+1]\n",
    "    parsers = model_name.split('-')\n",
    "    \n",
    "    # configs - varying\n",
    "    config = Config()\n",
    "    config.DEVICE = torch.device(f'cuda:{gpu_no}')\n",
    "    config.tag = None\n",
    "    config_dict = {'data_type':'simulation',\n",
    "                   'hedging_task':parsers[2] + '-' + parsers[3],\n",
    "                   'asset_model':parsers[4].split('_')[-1],\n",
    "                   'burnin_len':int(parsers[5].split('_')[-1]),\n",
    "                   'history_len':int(parsers[7].split('_')[-1]),\n",
    "                   'lam':float(parsers[8].split('_')[-1]),\n",
    "                   'lstm_hiddensize':int(parsers[9].split('_')[-1]),\n",
    "                   'lstm_inputsize':int(parsers[10].split('_')[-1]),\n",
    "                   'nn_model':parsers[11].split('_')[-1],\n",
    "                   'option_type':parsers[12].split('_')[-1],\n",
    "                   'strike_price':float(parsers[13].split('_')[-1])\n",
    "                   }\n",
    "    \n",
    "    # configs - fixed\n",
    "    config_dict.setdefault('log_level', 0)\n",
    "    config_dict.setdefault('action_noise', 0)\n",
    "    config.merge(config_dict)\n",
    "\n",
    "    config.task = parsers[2]\n",
    "    task = config.task\n",
    "    config.task_fn = lambda: Task(config.hedging_task, action_noise=config.action_noise, config=config)\n",
    "    config.eval_env = config.task_fn()\n",
    "    config.eval_interval = int(5e4)\n",
    "    config.eval_episodes = 1000\n",
    "    config.actor_encoding_size = 3\n",
    "    config.critic_encoding_size = 4\n",
    "\n",
    "    config.network_fn = lambda: RTD3Net(\n",
    "        config.state_dim,\n",
    "        config.action_dim,\n",
    "        config.actor_encoding_size,\n",
    "        config.critic_encoding_size,\n",
    "        actor_body_fn=lambda: OneDenseLSTM(config.state_dim+config.action_dim, config.lstm_inputsize,\n",
    "                                       config.lstm_hiddensize, config=config, gate=F.relu),\n",
    "        critic_body_fn=lambda: OneDenseLSTM(\n",
    "            config.state_dim+config.action_dim, config.lstm_inputsize, config.lstm_hiddensize,\n",
    "            config=config, gate=F.relu),\n",
    "        actor_opt_fn=lambda params: torch.optim.Adam(params, lr=1e-3),\n",
    "        critic_opt_fn=lambda params: torch.optim.Adam(params, lr=1e-3),\n",
    "    config=config)\n",
    "\n",
    "\n",
    "    config.discount = 0.99\n",
    "    config.td3_delay = 2\n",
    "    config.warm_up = int(1e4)\n",
    "    config.target_network_mix = 5e-3\n",
    "    config.replay_fn = lambda: Replay(memory_size=int(5e4), batch_size=100)\n",
    "    config.random_process_fn = lambda: GaussianProcess(\n",
    "        size=(config.action_dim,), std=LinearSchedule(0.1))\n",
    "    config.td3_noise = 0.2\n",
    "    config.td3_noise_clip = 0.5\n",
    "    config.td3_delay = 2\n",
    "    return model_name, file_list, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nas1/yjun/research_deep_hedging/codes/model/t0-MVPITD3Agent-DeltaHedging-v0-asset_model_Heston-burnin_len_5-data_type_simulation-history_len_10-lam_0.5-lstm_hiddensize_24-lstm_inputsize_6-nn_model_lstm-option_type_C-strike_price_100.0-run-0-18000.model\n",
      "<agent.MVPITD3_agent.MVPITD3Agent object at 0x7fe93033e310>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RTD3Net:\n\tsize mismatch for fc_current_obs.weight: copying a param with shape torch.Size([6, 7]) from checkpoint, the shape in current model is torch.Size([3, 7]).\n\tsize mismatch for fc_current_obs.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for fc_action.weight: copying a param with shape torch.Size([1, 30]) from checkpoint, the shape in current model is torch.Size([1, 27]).\n\tsize mismatch for fc_current_ac_obs1.weight: copying a param with shape torch.Size([7, 8]) from checkpoint, the shape in current model is torch.Size([4, 8]).\n\tsize mismatch for fc_current_ac_obs1.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for fc_current_ac_obs2.weight: copying a param with shape torch.Size([7, 8]) from checkpoint, the shape in current model is torch.Size([4, 8]).\n\tsize mismatch for fc_current_ac_obs2.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for fc_critic_1.weight: copying a param with shape torch.Size([1, 31]) from checkpoint, the shape in current model is torch.Size([1, 28]).\n\tsize mismatch for fc_critic_2.weight: copying a param with shape torch.Size([1, 31]) from checkpoint, the shape in current model is torch.Size([1, 28]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_199460/3773638206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtd3_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstate_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hedge/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RTD3Net:\n\tsize mismatch for fc_current_obs.weight: copying a param with shape torch.Size([6, 7]) from checkpoint, the shape in current model is torch.Size([3, 7]).\n\tsize mismatch for fc_current_obs.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for fc_action.weight: copying a param with shape torch.Size([1, 30]) from checkpoint, the shape in current model is torch.Size([1, 27]).\n\tsize mismatch for fc_current_ac_obs1.weight: copying a param with shape torch.Size([7, 8]) from checkpoint, the shape in current model is torch.Size([4, 8]).\n\tsize mismatch for fc_current_ac_obs1.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for fc_current_ac_obs2.weight: copying a param with shape torch.Size([7, 8]) from checkpoint, the shape in current model is torch.Size([4, 8]).\n\tsize mismatch for fc_current_ac_obs2.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for fc_critic_1.weight: copying a param with shape torch.Size([1, 31]) from checkpoint, the shape in current model is torch.Size([1, 28]).\n\tsize mismatch for fc_critic_2.weight: copying a param with shape torch.Size([1, 31]) from checkpoint, the shape in current model is torch.Size([1, 28])."
     ]
    }
   ],
   "source": [
    "reward_list = []\n",
    "total_sum_array = np.zeros(0)\n",
    "total_mean_array = np.zeros(0)\n",
    "total_std_array = np.zeros(0)\n",
    "total_delta_pnl_array = np.zeros(0)\n",
    "\n",
    "# trial_num\n",
    "trial_list = [0]\n",
    "for t in trial_list:\n",
    "    model_name, file_list, config = create_config(t)\n",
    "    td3_agent = MVPITD3Agent(config)\n",
    "    \n",
    "    for file in file_list:\n",
    "        filename = './codes/model/' + file\n",
    "\n",
    "        state_dict = torch.load(filename)\n",
    "        td3_agent.network.load_state_dict(state_dict)\n",
    "\n",
    "        state_list = []\n",
    "        action_array = np.array([])\n",
    "        action_mean_array = np.array([])\n",
    "        delta_array = np.array([])\n",
    "        reward_array = np.array([])\n",
    "        delta_pnl_array = np.array([])\n",
    "        \n",
    "        deltahedging_env = DeltaHedgingEnv(config, seed=0)\n",
    "        \n",
    "        for i in tqdm(range(100)):\n",
    "\n",
    "            done = False\n",
    "            state = deltahedging_env.reset()\n",
    "            while not done:\n",
    "                state = state.reshape(1,-1)\n",
    "                action = td3_agent.eval_step(state, history=td3_agent.history)\n",
    "                td3_agent.history.append(np.hstack([state, action]).flatten())\n",
    "                delta = deltahedging_env.env_params.delta.copy()\n",
    "                next_state, hedging_performance, done, _ = deltahedging_env.step(action, delta_check=True)\n",
    "                if not done:\n",
    "                    state_list.append(state)\n",
    "                    action_array = np.append(action_array, action)\n",
    "                    reward_array = np.append(reward_array, hedging_performance[0])\n",
    "                    delta_pnl_array = np.append(delta_pnl_array, hedging_performance[1])\n",
    "                    delta_array = np.append(delta_array, delta)\n",
    "                    state = next_state\n",
    "                    \n",
    "            td3_agent.history_reset(config)         \n",
    "            reward_list.append([reward_array.sum(), reward_array.mean(), reward_array.std()])\n",
    "            \n",
    "        print(str(model_name) + '\\n' + str(model_index))\n",
    "        \n",
    "        total_delta_pnl_array = np.append(total_delta_pnl_array, delta_pnl_array)\n",
    "        \n",
    "        total_sum_array = np.append(total_sum_array, np.array(reward_list)[:,0].mean())\n",
    "        total_mean_array = np.append(total_mean_array, np.array(reward_list)[:,1].mean())\n",
    "        total_std_array = np.append(total_std_array, np.array(reward_list)[:,2].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hedge",
   "language": "python",
   "name": "hedge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
